{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuisKolb/viz2-2023S/blob/main/feature_space_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "NYv32LAyQ6aY",
        "outputId": "ddd87d3f-6bc4-4b51-fba6-edd6f6acc10d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.decomposition import PCA\n",
        "import itertools\n",
        "import os"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q3ZSyk_TQBC"
      },
      "source": [
        "## IRIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0, 'sepal length (cm)') (1, 'sepal width (cm)')\n",
            "Correct samples: 111\n",
            "Incorrect samples: 39\n",
            "(0, 'sepal length (cm)') (2, 'petal length (cm)')\n",
            "Correct samples: 143\n",
            "Incorrect samples: 7\n",
            "(0, 'sepal length (cm)') (3, 'petal width (cm)')\n",
            "Correct samples: 144\n",
            "Incorrect samples: 6\n",
            "(1, 'sepal width (cm)') (2, 'petal length (cm)')\n",
            "Correct samples: 140\n",
            "Incorrect samples: 10\n",
            "(1, 'sepal width (cm)') (3, 'petal width (cm)')\n",
            "Correct samples: 143\n",
            "Incorrect samples: 7\n",
            "(2, 'petal length (cm)') (3, 'petal width (cm)')\n",
            "Correct samples: 144\n",
            "Incorrect samples: 6\n"
          ]
        }
      ],
      "source": [
        "# dataset file generation\n",
        "\n",
        "# base_dir = 'src/resources/iris'\n",
        "base_dir = \"files_out/iris/\"\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "\n",
        "for combination in list(itertools.combinations(enumerate(iris.feature_names), 2)):\n",
        "    print(combination[0], combination[1])\n",
        "\n",
        "    # Select the features to use for classification\n",
        "    X = iris.data[\n",
        "        :, [combination[0][0], combination[1][0]]\n",
        "    ]  # sepal length and petal width\n",
        "    y = iris.target\n",
        "\n",
        "    # print(f'min(X0)={min(X[:,0])}   ; max(X0)={max(X[:,0])} ;   step(X0)={(max(X[:,0])-min(X[:,0]))/100}')\n",
        "\n",
        "    # Split the dataset into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Train a neural network classifier with a logistic output layer\n",
        "    clf = MLPClassifier(\n",
        "        hidden_layer_sizes=(7,),\n",
        "        max_iter=5000,\n",
        "        random_state=42,\n",
        "        activation=\"logistic\",\n",
        "        solver=\"adam\",\n",
        "        alpha=0.0001,\n",
        "        batch_size=\"auto\",\n",
        "        learning_rate=\"constant\",\n",
        "        learning_rate_init=0.001,\n",
        "        power_t=0.5,\n",
        "        momentum=0.9,\n",
        "        nesterovs_momentum=True,\n",
        "        early_stopping=False,\n",
        "        validation_fraction=0.1,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-08,\n",
        "        n_iter_no_change=10,\n",
        "        tol=0.0001,\n",
        "        verbose=False,\n",
        "        warm_start=False,\n",
        "    )\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Test classifier\n",
        "    # Use the trained classifier to make predictions on the test dataset\n",
        "    y_pred = clf.predict(np.concatenate((X_train, X_test), axis=0))\n",
        "\n",
        "    # Compare the predicted labels with the true labels\n",
        "    correct_samples = sum(y_pred == np.concatenate((y_train, y_test), axis=0))\n",
        "    incorrect_samples = sum(y_pred != np.concatenate((y_train, y_test), axis=0))\n",
        "\n",
        "    # Print the number of correct and incorrect identified samples\n",
        "    print(f\"Correct samples: {correct_samples}\")\n",
        "    print(f\"Incorrect samples: {incorrect_samples}\")\n",
        "\n",
        "    # Generate a grid of feature combinations ()\n",
        "    grid_size = 60  # controls plot \"resolution\"\n",
        "    X0_range = np.arange(\n",
        "        min(X[:, 0]), max(X[:, 0]), (max(X[:, 0]) - min(X[:, 0])) / grid_size\n",
        "    )\n",
        "    X1_range = np.arange(\n",
        "        min(X[:, 1]), max(X[:, 1]), (max(X[:, 1]) - min(X[:, 1])) / grid_size\n",
        "    )\n",
        "    X0, X1 = np.meshgrid(X0_range, X1_range)\n",
        "    X_grid = np.column_stack((X0.ravel(), X1.ravel()))\n",
        "\n",
        "\n",
        "    # Predict the class probabilities for each feature combination\n",
        "    y_grid_prob = clf.predict_proba(X_grid)\n",
        "\n",
        "    if not os.path.exists(base_dir):\n",
        "      os.makedirs(base_dir)\n",
        "    \n",
        "    for i, class_name in enumerate(iris.target_names):\n",
        "        # save format: X0 X1 <probability of class 1> <probability of class 2> <probability of class 3>\n",
        "        X0_X1_classprobs = np.column_stack((X_grid, y_grid_prob))\n",
        "        np.savetxt(\n",
        "            fname=f\"{base_dir}/{combination[0][1]}_vs_{combination[1][1]}.txt\",\n",
        "            X=X0_X1_classprobs,\n",
        "            delimiter=\",\",\n",
        "            header=f\"{combination[0][1]},{combination[1][1]},{','.join(iris.target_names)}\",\n",
        "            comments=\"\"\n",
        "        )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## palmerpenguins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\josch\\AppData\\Local\\Temp\\ipykernel_11600\\1640023497.py:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  penguins.feature_names = [\"bill_length_mm\",\"bill_depth_mm\",\"flipper_length_mm\",\"body_mass_g\"]\n",
            "C:\\Users\\josch\\AppData\\Local\\Temp\\ipykernel_11600\\1640023497.py:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  penguins.data = penguins[penguins.feature_names]\n",
            "C:\\Users\\josch\\AppData\\Local\\Temp\\ipykernel_11600\\1640023497.py:13: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  penguins.target_names = [\"Torgersen\", \"Biscoe\", \"Dream\"]\n",
            "C:\\Users\\josch\\AppData\\Local\\Temp\\ipykernel_11600\\1640023497.py:14: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  penguins.target = pd.factorize(penguins[\"species\"])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['bill_length_mm', 'bill_depth_mm']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\josch\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct samples: 322\n",
            "Incorrect samples: 11\n",
            "['bill_length_mm', 'flipper_length_mm']\n",
            "Correct samples: 246\n",
            "Incorrect samples: 87\n",
            "['bill_length_mm', 'body_mass_g']\n",
            "Correct samples: 146\n",
            "Incorrect samples: 187\n",
            "['bill_depth_mm', 'flipper_length_mm']\n",
            "Correct samples: 265\n",
            "Incorrect samples: 68\n",
            "['bill_depth_mm', 'body_mass_g']\n",
            "Correct samples: 146\n",
            "Incorrect samples: 187\n",
            "['flipper_length_mm', 'body_mass_g']\n",
            "Correct samples: 146\n",
            "Incorrect samples: 187\n"
          ]
        }
      ],
      "source": [
        "# dataset file generation\n",
        "\n",
        "# base_dir = 'src/resources/penguins'\n",
        "base_dir = \"files_out/penguins/\"\n",
        "\n",
        "# Load the penguins dataset\n",
        "penguins = pd.read_csv(\"data/penguins.csv\")\n",
        "penguins.dropna(inplace=True)\n",
        "# display(penguins.isna().sum())\n",
        "penguins.feature_names = [\"bill_length_mm\",\"bill_depth_mm\",\"flipper_length_mm\",\"body_mass_g\"]\n",
        "penguins.data = penguins[penguins.feature_names]\n",
        "\n",
        "penguins.target_names = [\"Torgersen\", \"Biscoe\", \"Dream\"]\n",
        "penguins.target = pd.factorize(penguins[\"island\"])\n",
        "\n",
        "\n",
        "for combination in list(itertools.combinations(enumerate(penguins.feature_names), 2)):\n",
        "    print([combination[0][1], combination[1][1]])\n",
        "\n",
        "    X1 = combination[0][1]\n",
        "    \n",
        "    X2 = combination[1][1]\n",
        "    # Select the features to use for classification\n",
        "    X = penguins[[X1, X2]] \n",
        "    y = penguins.target[0]\n",
        "\n",
        "    # Split the dataset into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Train a neural network classifier with a logistic output layer\n",
        "    clf = MLPClassifier(\n",
        "        hidden_layer_sizes=(5,),\n",
        "        max_iter=1000,\n",
        "        random_state=42,\n",
        "        activation=\"logistic\",\n",
        "        solver=\"adam\",\n",
        "        alpha=0.0001,\n",
        "        batch_size=\"auto\",\n",
        "        learning_rate=\"constant\",\n",
        "        learning_rate_init=0.001,\n",
        "        power_t=0.5,\n",
        "        momentum=0.9,\n",
        "        nesterovs_momentum=True,\n",
        "        early_stopping=False,\n",
        "        validation_fraction=0.1,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-08,\n",
        "        n_iter_no_change=10,\n",
        "        tol=0.0001,\n",
        "        verbose=False,\n",
        "        warm_start=False,\n",
        "    )\n",
        "    clf.fit(X_train.values, y_train)\n",
        "\n",
        "    # Test classifier\n",
        "    # Use the trained classifier to make predictions on the test dataset\n",
        "    y_pred = clf.predict(np.concatenate((X_train, X_test), axis=0))\n",
        "\n",
        "    # Compare the predicted labels with the true labels\n",
        "    correct_samples = sum(y_pred == np.concatenate((y_train, y_test), axis=0))\n",
        "    incorrect_samples = sum(y_pred != np.concatenate((y_train, y_test), axis=0))\n",
        "\n",
        "    # Print the number of correct and incorrect identified samples\n",
        "    print(f\"Correct samples: {correct_samples}\")\n",
        "    print(f\"Incorrect samples: {incorrect_samples}\")\n",
        "\n",
        "    # Generate a grid of feature combinations ()\n",
        "    grid_size = 20  # controls plot \"resolution\"\n",
        "    X0_range = np.arange(\n",
        "        X.min()[0], X.max()[0], (X.max()[0] - X.min()[0]) / grid_size\n",
        "    )\n",
        "    X1_range = np.arange(\n",
        "        X.min()[1], X.max()[1], (X.max()[1] - X.min()[1]) / grid_size\n",
        "    )\n",
        "    X0, X1 = np.meshgrid(X0_range, X1_range)\n",
        "    X_grid = np.column_stack((X0.ravel(), X1.ravel()))\n",
        "\n",
        "\n",
        "    # Predict the class probabilities for each feature combination\n",
        "    y_grid_prob = clf.predict_proba(X_grid)\n",
        "\n",
        "\n",
        "    if not os.path.exists(base_dir):\n",
        "      os.makedirs(base_dir)\n",
        "    \n",
        "    for i, class_name in enumerate(penguins.target_names):\n",
        "        # save format: X0 X1 <probability of class 1> <probability of class 2> <probability of class 3>\n",
        "        X0_X1_classprobs = np.column_stack((X_grid, y_grid_prob))\n",
        "        np.savetxt(\n",
        "            fname=f\"{base_dir}/{combination[0][1]}_vs_{combination[1][1]}.txt\",\n",
        "            X=X0_X1_classprobs,\n",
        "            delimiter=\",\",\n",
        "            header=f\"{combination[0][1]},{combination[1][1]},{','.join(penguins.target_names)}\",\n",
        "            comments=\"\"\n",
        "        )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP3U/OTdgiMPVwk2Of2RKTB",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
